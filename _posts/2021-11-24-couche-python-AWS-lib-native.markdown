---
layout: post
title:  "Construire pour AWS sa couche python comportant des bibliothÃ¨ques natives"
date:   2021-11-25 18:19:52 +0100
categories: jekyll update
---

## TL; DR;

Ce billet peut intÃ©resser qui a besoin d'ajouter dans une lambda AWS des lib python native, c'est Ã  dire qui doivent Ãªtre compilÃ©es sur l'environnement cible. Comme numpy par exemple, ou en ce qui me concernait ici, pycurl. Pour faire court, vous pouvez aller sur le poste StackOverFlow associÃ©Â : [https://stackoverflow.com/questions/67729764/errors-when-trying-to-call-pycurl-in-a-lambda-on-aws](https://stackoverflow.com/questions/67729764/errors-when-trying-to-call-pycurl-in-a-lambda-on-aws)

Mais j'ai trouvÃ© que le chemin Ã©tait aussi intÃ©ressant que l'arrivÃ©e (mÃªme si Ã§a fait toujours plaisir de faire son premier sommet Ã  4000 mÃ¨tres - ce qui a Ã©tÃ© un peu mon impression un fois arrivÃ© ). C'est ce chemin que je vous propose de partager ici.

## Les motivations du voyage


Je trouve le blog d'Arolla long Ã  charger, de mÃªme que les deux sites perso d'une amie et le mien. J'aimerais rendre Ã§a objectif en mettant une petite sonde, car je n'ai pas accÃ¨s Ã  google analytics. Je demande Ã  Netvigie, c'est une dizaine d'euros par mois par URL. Je me dis qu'une lambda AWS pourrait faire la mesure, puis pousser Ã§a dans un Elasticsearch, surtout qu'AWS propose un service Elasticsearch tout fait.

## Jour 1, matinÂ : arrivÃ©e sans encombre au camp de base local


![carte jour 1](/media/Layer-AWS-carte-j1.png)

En une heure, j'ai ma stack OpenSearch (ex Â« ELK Â») dÃ©ployÃ©e dans AWS, par la console, en mode light vraiment pas sÃ©curisÃ©, grÃ¢ce au tuto officiel : [https://docs.aws.amazon.com/opensearch-service/latest/developerguide/gsgcreate-domain.html](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/gsgcreate-domain.html)

Deux heures plus tard, j'ai un bout de code en local qui tourne dans mon PyCharm, qui me permet de voir mes premiÃ¨res donnÃ©es dans Kibana [(1)](#note1).  
[https://github.com/edouard-gv/web-monitor/blob/f22f17058ced0ec69cef8cd5c9c1b774b640d760/monitor.py](https://github.com/edouard-gv/web-monitor/blob/f22f17058ced0ec69cef8cd5c9c1b774b640d760/monitor.py)

![mesures](/media/Layer-AWS-PremiÃ¨res-mesures-manuelles.png)

Avec les requirements suivantÂ :

*   pycurl~=7.43.0.5
*   certifi~=2020.12.5
*   requests~=2.25.1

Pourquoi PyCurlÂ ? Car c'Ã©tait, d'aprÃ¨s moi, la seule librairie qui permette de mesurer les diffÃ©rents temps rÃ©seau finement, notamment le temps de rÃ©solution DNS.

Bref, Ã§a marche sur mon environnement localÂ : j'Ã©tais arrivÃ© sans encombre au camp de base. Mais, comme parfois, c'est le passage dans l'environnement de prod qui va se rÃ©vÃ©ler le plus long. Surtout si celui-ci est dans le cloud.

Ce n'est en effet que deux jours plus tard que j'arriverai Ã  faire fonctionner ce code dans une lambda.

### Quand il ne suffit pas de copier le code en prod

Le souci vient que mon code rÃ©fÃ©rence trois librairies, dont une native, `pycurl`. VoilÃ  donc ce que j'avais comme erreur en lanÃ§ant le code dans une lambdaÂ :

    Unable to import module 'lambda\_function': No module named 'pycurl';

Pour celles ou ceux qui me proposent d'utiliser une autre lib que `pycurl`, comme `libcurl2`, j'ai deux rÃ©ponsesÂ : la premiÃ¨re, comme je le disais en introduction, c'est que `libcurl2` ne me donnent pas les temps de rÃ©solution de DNS, temps du premier octet, temps du dernier octet, cf [https://stackoverflow.com/questions/744532/getting-ttfb-time-till-first-byte-for-an-http-request](https://stackoverflow.com/questions/744532/getting-ttfb-time-till-first-byte-for-an-http-request). La seconde, Boulet l'illustre mieux que moi ğŸ˜‰Â : [http://www.bouletcorp.com/2021/03/05/conseils-depannage/](http://www.bouletcorp.com/2021/03/05/conseils-depannage/).

### AprÃ¨s-midiÂ : perdu dans la forÃªt des services AWS

PremiÃ¨re Ã©tape : comprendre que j'ai besoin de construire une couche lambda (lambda layer), c'est-Ã -dire un endroit oÃ¹ mettre les lib python dont dÃ©pend mon code. J'avais vu Ã§a sur un autre projet, oÃ¹ les lib Ã©taient comitÃ©es dans le code dans des sous-repertoires layer/â€¦, qui Ã©tait dÃ©ployÃ©s par la chaine CI/CD que je n'avais pas regardÃ©e de prÃ¨s sur cette partie-lÃ . De toutes faÃ§ons, on ne les utilisait pas en local car c'Ã©taient Â« les versions pour la prod Â», et Ã§a avait Ã©tÃ© mis par les architectes AWS, ils savaient ce qu'ils faisaient (aujourd'hui je ferai autrement).

En tous cas, je comprends qu'il va falloir construire cette couche lambda, contenant les lib python. Je chausse mes crampons stackoverflow et je quitte le camp de base.

LÃ , j'ai dÃ» dÃ©fragmenter cette partie du cerveau oÃ¹ commenÃ§aient Ã  s'empiler mes expÃ©riences AWS. Je me souvenais avoir utilisÃ© des pipelines qui utilisaient des images pour compiler. Et puis y a CodeDeploy, CloudFormation. J'ai cherchÃ© un peu par-lÃ , en me demandant s'il fallait que je crÃ©e une pipeline pour construire mon image Ã  dÃ©ployer, mÃ©langeant avec ce qu'on doit faire quand on dÃ©ploie une lambda en java.

Je me suis bien perdu, et j'ai donc dÃ» revenir au camp de base, la nuit tombait.

## Jour 2Â : sur le bon chemin du col, on croise un drÃ´le d'oiseau DLL

![carte jour 2](/media/Layer-AWS-carte-j2.png)

AprÃ¨s une nuit de sommeil, les idÃ©es plus au clair et donc mes recherches google mieux dirigÃ©es, je suis tombÃ© sur un tuto du support aws [https://aws.amazon.com/fr/premiumsupport/knowledge-center/lambda-layer-simulated-docker/](https://aws.amazon.com/fr/premiumsupport/knowledge-center/lambda-layer-simulated-docker/)

L'idÃ©e est simplement de zipper les librairies organisÃ©es suivant la bonne hiÃ©rarchie. DÃ©veloppant sur une Surface Go, sans docker, sous windows, j'ai commencÃ© Ã  essayer de copier et zipper les librairies que PyCharm avaient ajoutÃ© dans mon venv, mais je ne suis pas allÃ© au bout, il y a trop de choses. Et Ã§a commenÃ§ait Ã  sentir pas trÃ¨s bonÂ : je vois une DLL pour pycurl dans mes lib python pycharm. Je me dis bien que Ã§a ne va pas tourner sur les env linux d'AWS lambda... L'orage grondait...

C'est bien pour Ã§a que le tuto propose de passer par une image docker pour gÃ©nÃ©rer les dÃ©pendances. Du coup je change de PC (un vieux portable linux), et je suis le tuto pas Ã  pas (sauf quand le tuto propose d'uploader le zip via le CLIÂ : si comme moi vous ne voulez pas utiliser le CLI, on peut trouver dans la console oÃ¹ uploader les zip).

### Jour 2, midiÂ : le ciel s'obscurcitÂ , pycurl a besoin de dÃ©pendances natives

Le tuto ne fonctionne pasÂ : la construction via `pip` de la librairy `pycurl` demande des dÃ©pendances qui ne sont pas sur l'image docker fournie pourtant par AWS. Dans le fatras des messages d'erreur, la ligne qui m'intÃ©resse est celle-ciÂ :

    Could not run curl-config: \[Errno 2\] No such file or directory: 'curl-config': 'curl-config';

Je teste quand mÃªme le process complet mais sur le code dont j'ai commentÃ© les dÃ©pendance `pycurl`, avec un `requirements.txt` qui ne contient donc que `certifi` et `requests`Â : construction de la layer dans un rÃ©pertoire vide, zip et upload, et j'ai ma premiÃ¨re victoire, le ciel s'Ã©claircit, j'ai l'impression d'Ãªtre arrivÃ© au pied du bon col. J'y planterai ma tente.

Dans le dÃ©tail, Ã§a consiste Ã Â :

1.  mettre `requirements.txt` dans un rÃ©pertoire vide
1.  lancer `docker run -v "$PWD":/var/task "public.ecr.aws/sam/build-python3.6" /bin/sh -c "pip install -r requirements.txt -t python/lib/python3.6/site-packages/; exit"`
1.  zipper le repertoire gÃ©nÃ©rÃ© `zip -r mypythonlibs.zip python > /dev/null`
1.  uploader ce zip comme une couche lambda dans la console, et toujours dans la console rÃ©fÃ©rencer cette couche dans la configuration de la lambda
1.  BonusÂ : supprimer (en sudo) le rÃ©pertoire gÃ©nÃ©rÃ©, pour ne pas oublier de le faire Ã  l'itÃ©ration suivante

Je me dis que je pourrais quand mÃªme tenter un raccourciÂ : je fais l'hypothÃ¨se que les librairies linux devraient quand mÃªme se ressembler, et tente de gÃ©nÃ©rer la couche via mon ubuntu, sans passer par l'image docker, ce qui revient Ã  simplement lancer dans un rÃ©pertoire ne contenant que `requirements.txt` la commande `pip install -r requirements.txt -t python/lib/python3.6/site-packages/` (en lieu du 2. de la sÃ©quence prÃ©cÃ©dente).

Mais mon ubuntu n'est pas AWS compatible, j'ai l'erreur suivante quand je lance la lambdaÂ :

    Unable to import module 'lambda\_function': libssl.so.1.0.0: cannot open shared object file: No such file or directory

Je retourne me coucher dans ma tente...

## Jour 3Â : construire sa propre image docker pour gÃ©nÃ©rer la couche lambda


![carte jour 3](/media/Layer-AWS-carte-j3.png)

En surfant un peu, je commence Ã  sentir qu'il va bien falloir que je me dÃ©batte avec une image docker ad-hoc. Je crois que ce qui m'a mis sur le chemin est cet article-lÃ Â : [https://github.com/awslabs/serverless-image-handler/issues/44](https://github.com/awslabs/serverless-image-handler/issues/44), Ã§a n'avait rien Ã  voir, mais il Ã©tait sorti en tapant pycurl aws dans google.

LÃ , il a fallu que je dÃ©fragmente mes souvenirs docker, Ã§a faisait plus d'un an que je n'avais pas construit une image docker. Mais c'est comme le vÃ©lo. Je suis arrivÃ© assez vite Ã  construire une image Ã  partir de ce dockerfileÂ :

    FROM public.ecr.aws/sam/build-python3.6
    
    RUN yum install libcurl-devel python36-devel -y
    
    RUN yum install nss-devel -y
    ENV PYCURL\_SSL\_LIBRARY=nss

Sans oublier les -y aprÃ¨s les yum.

Donc, pour construire ma couche, au lieu d'utiliser l'image d'aws classique, je devais utiliser la mienneÂ :

*   En la construisant via `docker build -t build-python3.6-with-pycurl`
*   Puis en l'utilisant Ã  l'Ã©tape 2Â : `docker run -v "$PWD":/var/task "public.ecr.aws/sam/build-python3.6-with-pycurl" /bin/sh -c "pip install -r requirements.txt -t python/lib/python3.6/site-packages/; exit"` (noter le nom de mon image `build-python3.6-with-pycurl` au lieu de `build-python3.6`)

J'ai dÃ» faire quelques itÃ©rations, ajouter les dÃ©pendances les unes aprÃ¨s les autres, comme chaque fois une petite montÃ©e Ã  gravir. Jusqu'Ã  arriver devant une montÃ©e un peu plus abrupte que les autresÂ : je tombai sur cette insulte de gcc (alors qu'on ne s'Ã©tait pas parlÃ© depuis quinze ans au moinsÂ !)
    
    src/pycurl.h:5:10: fatal error: Python.h: No such file or directory
         #include <Python.h>
                  ^~~~~~~~~~
        compilation terminated.
        error: command 'gcc' failed with exit status 1
    
J'ai cru Ãªtre Ã  nouveau dans une impasse, mais c'Ã©tait juste qu'il y avait un dernier petit raidillon avant le col ouvrant sur le chemin large menant au sommet...

### Le raidillon du lien symbolique

Pour une raison que j'ignore, la distribution linux d'AWS ne met pas ses header C lÃ  oÃ¹ d'autres l'imagineraient. C'est en fouinant toujours sur StackOverFlow, que je voyais que les rÃ©ponses Ã  ce genre de question Ã©taient : Â« sais-tu oÃ¹ est Python.h Â» ? Facile sur son poste, mais sur une image Docker qu'on lance en exec... ObligÃ© de me rappeler comment me loguer en ssh sur une image docker, retrouver la syntaxe de find, greper tout Ã§a, me rendre compte que c'est dans `/var/lang/include`, dÃ©crypter la commande `gcc` et les `-I` pour me rendre compte que gcc s'attend d'avoir ses header file dans `/usr/include`.  
Et tant que j'Ã©tais en ssh sur mon image, j'ai pu y faire directement mes itÃ©rations (c'est Ã  dire lancer le `pip install` dans mon image), pour me rendre compte qu'il suffisait juste de faire le bon lien symbolique, que j'ai ensuite recopiÃ© dans mon dockerfile, qui est devenuÂ :

    FROM public.ecr.aws/sam/build-python3.6
    
    RUN yum install libcurl-devel python36-devel -y
    
    RUN yum install nss-devel -y
    ENV PYCURL\_SSL\_LIBRARY=nss
    
    RUN ln -s /usr/include /var/lang/include

Je suis confiant, le col est en vue, plus qu'Ã  lancer la construction via cette nouvelle image docker.

### Le ruisseau du backend ssl

Effectivement, gcc ne dit plus rien, ma nouvelle couche est lÃ , plus qu'Ã  la zipper, l'uploader, la faire rÃ©fÃ©rencer par ma lambda. ForcÃ©ment, je me prends les pieds dans un dernier ruisseau, Ã  force de copier bÃªtement de stackoverflow, je n'avais pas le bon backend ssl Ã  l'exÃ©cution dans AWSÂ :

    pycurl: libcurl link-time ssl backend (openssl) is different from compile-time ssl backend (nss)

Mais le guÃ© pour franchir le ruisseau n'est pas loin, une petite modification dans le docker fileÂ :

    FROM public.ecr.aws/sam/build-python3.6
    
    RUN yum install libcurl-devel python36-devel -y
    
    RUN yum install openssl-devel -y
    ENV PYCURL\_SSL\_LIBRARY=openssl
    
    RUN ln -s /usr/include /var/lang/include

### Lâ€™arrivÃ©e au sommet !

On relance tout (image, layer, zip, upload), comme un dernier petit sprint, et c'est l'arrivÃ©e au sommet, sous le soleil !

J'ai pu profiter de la vue en mangeant mon sandwich, et j'imaginais le programme pour le prochain week-end de randoÂ : pouvoir dÃ©ployer ma lambda en automatique (CI/CD).

## Dâ€™autres chemins


Depuis, j'ai dÃ©couvert que j'aurais pu passer par d'autres chemins, notamment en suivant celles et ceux qui ont cherchÃ© Ã  installer numpy / panda, et qui sont beaucoup plus nombreux. J'ai ainsi entendu parler des sentiers suivantsÂ :

*   **Pour ne pas recompiler**. Le sentier des wheels (merci Dimitri)Â : si votre bibliothÃ¨que est publiÃ©e sous forme de wheel, vous pouvez dÃ©zipper celle correspondant Ã  \*manylinux1\_x86\_64.whl pour construire votre layer Ã  la main. ExempleÂ : [https://korniichuk.medium.com/lambda-with-pandas-fd81aa2ff25e](https://korniichuk.medium.com/lambda-with-pandas-fd81aa2ff25e)
*   **Pour recompiler, mais sans Docker**. Le sentier d'EC2 sur Amazon Linux, encore mieux balisÃ© via l'IDE cloud d'AWS, Cloud9Â : [https://towardsdatascience.com/python-packages-in-aws-lambda-made-easy-8fbc78520e30](https://towardsdatascience.com/python-packages-in-aws-lambda-made-easy-8fbc78520e30)
*   **Pour ne pas faire le lien symbolique**. Le sentier gcc, en rÃ©sinstallant gcc, g++ etc. dans l'image dockerÂ : [https://github.com/chedabob/LambdaZipper/blob/master/Dockerfile](https://github.com/chedabob/LambdaZipper/blob/master/Dockerfile)

## Tout Ã§a pour Ã§a

Ce que je ne savais pas, c'est que l'ECS Elastic-stack finalement me coÃ»tera plus cher qu'un abonnement Netvigie (30â‚¬ par mois), et qu'on ne peut pas l'Ã©teindre sans le supprimer. Un mois plus tard, je le supprimerai donc, sans avoir mÃªme rÃ©ussi Ã  sauvegarder les donnÃ©es que j'y avais indexÃ©es, n'ayant pas rÃ©ussi Ã  crÃ©er un snapshot de l'index [(2)](#note2).  
Ce n'est donc pas demain que je monterai un concurrent de NetVigieÂ :).

![carte gÃ©nÃ©rale](/media/Layer-AWS-carte.png)

* * *

[(1)](#ref1): En vrai j'ai changÃ© de modÃ¨le de donnÃ©e depuisÂ : avant, je poussais un objet par ping et par URL, avec les quatre mesures dans quatre attributs de cet objetÂ  maintenant je pousse quatre objets, un par mesure, avec le nom de la mesure dans un attribut. Bonne pratique data, plus facile Ã  gÃ©rer dans Kibana.

[(2)](#ref2): Si vous voulez savoir comment crÃ©er des snapshot d'index ESÂ : [https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains-snapshots.html#es-managedomains-snapshot-prerequisites](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains-snapshots.html#es-managedomains-snapshot-prerequisites). Comme d'habitude, c'est la gestion de la sÃ©curitÃ© qui pose le plus de soucis. Je me suis arrÃªtÃ© au message "Credential should be scoped to correct service: 'es'. " alors qu'il m'avait bien pourtant semblÃ© avoir modifiÃ© les relations d'approbation de maniÃ¨re Ã  y associer le fournisseur d'identitÃ© es.amazonaws.com.
